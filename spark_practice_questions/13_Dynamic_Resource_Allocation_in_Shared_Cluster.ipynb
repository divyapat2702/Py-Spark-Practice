{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca92834-39c4-4832-a6a3-963345c36a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 18px; margin-bottom: 15px;\">\n",
    "  <img src=\"https://files.codebasics.io/v3/images/sticky-logo.svg\" alt=\"Codebasics Logo\" style=\"display: inline-block;\" width=\"130\">\n",
    "  <h1 style=\"font-size: 34px; color: #1f4e79; margin: 0; display: inline-block;\">Codebasics Practice Room - Data Engineering Bootcamp </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b825085-0e4a-437a-a2e1-173a15a874d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### âš–ï¸ Dynamic Resource Allocation in a Shared Cluster\n",
    "\n",
    "This notebook demonstrates how to configure **Spark Dynamic Resource Allocation**\n",
    "so a job can **scale up when busy** and **release resources when idle**\n",
    "in a **shared YARN / Kubernetes cluster**.\n",
    "\n",
    "We use a **shuffle-heavy aggregation** on `big_events_50k.csv`\n",
    "to illustrate how Spark dynamically adjusts executors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28a4d61e-7927-4369-87ea-913d17d42a85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ“‚ Dataset\n",
    "\n",
    "**Dataset Name:** `big_events_50k.csv`  \n",
    "\n",
    "### Example Columns:\n",
    "- `event_id`\n",
    "- `event_time`\n",
    "- `country`\n",
    "- `device`\n",
    "- `amount`\n",
    "\n",
    "The dataset is large enough to:\n",
    "- create **shuffle-heavy stages**\n",
    "- demonstrate executor scaling behavior\n",
    "\n",
    "> âš ï¸ In real production systems, this dataset could be **hundreds of GBs**.\n",
    "> The same dynamic allocation pattern applies regardless of size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7f7517e-b501-411e-a88b-ba950bb0a112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ—‚ï¸ Scenario\n",
    "\n",
    "Your Spark job runs in a **shared cluster** (YARN or Kubernetes)\n",
    "used by multiple teams.\n",
    "\n",
    "Observed issues:\n",
    "- Sometimes your job **consumes too many executors**\n",
    "- Sometimes it **runs slowly due to lack of resources**\n",
    "- Static executor allocation causes:\n",
    "  - wasted resources when the job is idle\n",
    "  - unfair usage during peak times\n",
    "\n",
    "You want Spark to:\n",
    "- automatically scale up during heavy processing\n",
    "- release executors when work finishes\n",
    "- avoid impacting other teamsâ€™ jobs\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Task\n",
    "\n",
    "Using `big_events_50k.csv`, design a Spark job that:\n",
    "\n",
    "1. Enables **dynamic executor allocation**\n",
    "2. Sets sensible **min / initial / max executors**\n",
    "3. Safely handles shuffle data when executors are removed\n",
    "4. Releases idle executors automatically\n",
    "5. Works well in a **multi-tenant cluster**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Assumptions\n",
    "\n",
    "- Spark runs on **YARN or Kubernetes**\n",
    "- Cluster is shared by multiple teams\n",
    "- The job contains **shuffle-heavy operations**\n",
    "- Spark configs are set via:\n",
    "  - `spark-submit`\n",
    "  - cluster defaults\n",
    "  - or SparkSession builder\n",
    "\n",
    "> âš ï¸ Databricks Serverless manages resources automatically\n",
    "> and does **not allow manual dynamic allocation configuration**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Deliverables\n",
    "\n",
    "- A Spark job using **dynamic resource allocation**\n",
    "- Executors scale up during shuffle-heavy stages\n",
    "- Executors are released when idle\n",
    "- Job avoids starving other teams\n",
    "\n",
    "### Expected Behavior\n",
    "\n",
    "| Workload State | Executor Behavior |\n",
    "|---------------|-------------------|\n",
    "High shuffle load | Executors scale up |\n",
    "Idle periods | Executors released |\n",
    "Shared cluster | Fair resource usage |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Notes\n",
    "\n",
    "- Dynamic allocation is most useful in **shared clusters**\n",
    "- Spark decides executor count **at runtime**\n",
    "- Shuffle handling is critical for safe executor removal\n",
    "- This is a **configuration-level optimization**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19c8f072-b59c-42f8-8803-c10416fa5227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ§  Solution Strategy (High-Level)\n",
    "\n",
    "1. Enable Spark dynamic allocation\n",
    "2. Configure min, initial, and max executors\n",
    "3. Enable safe shuffle handling:\n",
    "   - external shuffle service (YARN)\n",
    "   - shuffle tracking (Kubernetes)\n",
    "4. Tune idle and backlog timeouts\n",
    "5. Run a shuffle-heavy aggregation on `big_events_50k.csv`\n",
    "\n",
    "Spark automatically:\n",
    "- adds executors when tasks back up\n",
    "- removes executors after idle timeout\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "13_Dynamic_Resource_Allocation_in_Shared_Cluster",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
