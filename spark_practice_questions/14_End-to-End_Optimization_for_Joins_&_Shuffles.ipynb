{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b0fa39-a605-43db-87ad-aeb38a8b0d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 18px; margin-bottom: 15px;\">\n",
    "  <img src=\"https://files.codebasics.io/v3/images/sticky-logo.svg\" alt=\"Codebasics Logo\" style=\"display: inline-block;\" width=\"130\">\n",
    "  <h1 style=\"font-size: 34px; color: #1f4e79; margin: 0; display: inline-block;\">Codebasics Practice Room - Data Engineering Bootcamp </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3561203-8421-473c-83f0-aaa6e64b2793",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### ðŸš€ End-to-End Optimization for Joins & Shuffles\n",
    "\n",
    "This notebook demonstrates **end-to-end performance optimization**\n",
    "for Spark pipelines involving **large joins and aggregations**.\n",
    "\n",
    "The focus is on **reducing shuffle cost**, which is the most expensive\n",
    "operation in distributed Spark workloads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a812c25-83c3-45fc-bf97-04c6888aaa29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ“‚ Dataset\n",
    "\n",
    "### Fact Table (Large)\n",
    "- **File:** `sales_orders_large.csv`\n",
    "\n",
    "\n",
    "**Schema**\n",
    "- order_id\n",
    "- order_date\n",
    "- region\n",
    "- customer_id\n",
    "- category\n",
    "- quantity\n",
    "- amount\n",
    "\n",
    "### Dimension Tables (Small)\n",
    "- `dim_customers_optim.csv`\n",
    "- `dim_category_group_optim.csv`\n",
    "\n",
    "> The fact table is much larger than the dimensions.  \n",
    "> Dimensions are small enough to be **broadcast safely**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d00007b-db40-4b48-b019-a47d8878afac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ—‚ï¸ Scenario\n",
    "\n",
    "You own a Spark pipeline that:\n",
    "\n",
    "- Reads **large historical sales data**\n",
    "- Joins with **multiple dimension tables**\n",
    "- Performs **aggregations for BI reporting**\n",
    "- Writes results to a warehouse\n",
    "\n",
    "As data grows:\n",
    "- Shuffle stages become very expensive\n",
    "- Job runtime increases significantly\n",
    "- Cluster resources are under pressure\n",
    "\n",
    "Your goal is to **optimize the entire pipeline end-to-end**\n",
    "to reduce shuffle cost and improve performance.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Task\n",
    "\n",
    "Apply end-to-end optimization strategies to:\n",
    "\n",
    "1. Reduce data scanned\n",
    "2. Reduce shuffle volume\n",
    "3. Optimize joins\n",
    "4. Improve file layout for downstream BI\n",
    "5. Make the pipeline scalable and production-ready\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Assumptions\n",
    "\n",
    "- Fact table is **much larger** than dimensions\n",
    "- Dimension tables are **small enough to broadcast**\n",
    "- Data is queried frequently by **date**\n",
    "- BI tools read aggregated outputs\n",
    "\n",
    "> This notebook focuses on **design patterns**, not just code.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Deliverables\n",
    "\n",
    "- Optimized join strategy\n",
    "- Reduced shuffle cost\n",
    "- Partitioned, analytics-friendly output\n",
    "- Clear before vs after comparison\n",
    "\n",
    "### Expected Outcome\n",
    "\n",
    "| Area | Improvement |\n",
    "|----|------------|\n",
    "Shuffle cost | Significantly reduced |\n",
    "Join performance | Faster via broadcast |\n",
    "IO | Reduced via partition pruning |\n",
    "Scalability | Improved |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Notes\n",
    "- Most Spark slowness comes from **shuffles**\n",
    "- Join strategy matters more than raw compute\n",
    "- File layout is as important as Spark code\n",
    "- Optimization is **holistic**, not one-line fixes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95b54b28-b38e-488d-a1f6-48dfb44acc41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ§  Solution Strategy (High-Level)\n",
    "\n",
    "1. Convert CSV â†’ Parquet/Delta (columnar, compressed)\n",
    "2. Partition fact data by `order_date`\n",
    "3. Filter and project early\n",
    "4. Broadcast small dimensions\n",
    "5. Tune shuffle partitions\n",
    "6. Write optimized output for BI\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "14_End-to-End_Optimization_for_Joins_&_Shuffles",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
