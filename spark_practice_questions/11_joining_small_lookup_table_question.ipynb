{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d493d205-0d6d-43c5-b959-8c966477deeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 18px; margin-bottom: 15px;\">\n",
    "  <img src=\"https://files.codebasics.io/v3/images/sticky-logo.svg\" alt=\"Codebasics Logo\" style=\"display: inline-block;\" width=\"130\">\n",
    "  <h1 style=\"font-size: 34px; color: #1f4e79; margin: 0; display: inline-block;\">Codebasics Practice Room - Data Engineering Bootcamp </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe92f04f-b724-4680-8114-bd92d82ae4a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîó Joining Small Lookup Tables Efficiently in Spark\n",
    "\n",
    "This notebook demonstrates how Apache Spark can **efficiently join a very large fact table**\n",
    "with a **small lookup (dimension) table** using a **broadcast join**.\n",
    "\n",
    "This is a common real-world pattern in analytics and data engineering,\n",
    "especially in **star-schema‚Äìlike designs**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e2bb9a7-5d1d-4928-a730-562dd860be41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìÇ Dataset\n",
    "\n",
    "### Fact Table (Large)\n",
    "**Dataset Name:** `big_events_50k.csv`  \n",
    "Represents a large transactional or event-level dataset.\n",
    "\n",
    "### Dimension Table (Small)\n",
    "**Dataset Name:** `country_dim.csv`  \n",
    "Contains country metadata such as country name and region.\n",
    "\n",
    "> ‚ö†Ô∏è In real-world systems, the fact table can contain **millions or billions of rows**,  \n",
    "while the country dimension usually contains **only a few hundred rows**.\n",
    "\n",
    "Both datasets are assumed to be available in **your catalog / database storage**.\n",
    "\n",
    "### Example Columns\n",
    "\n",
    "**Fact Table**\n",
    "- `event_id`\n",
    "- `event_time`\n",
    "- `country`\n",
    "- `amount`\n",
    "\n",
    "**Country Dimension**\n",
    "- `country_code`\n",
    "- `country_name`\n",
    "- `region_group`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3adcd9af-6e0e-4df2-9071-83269afa95b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üóÇÔ∏è Scenario\n",
    "\n",
    "You are working with a **large fact table** containing transaction or event data.\n",
    "Each record includes a **country code**, but no descriptive country information.\n",
    "\n",
    "To enrich the data for reporting, you need to join it with a **small country dimension table**\n",
    "that contains:\n",
    "- full country names\n",
    "- regional groupings (e.g., Asia, Europe, Americas)\n",
    "\n",
    "Because the fact table is large and the dimension table is very small,\n",
    "a **standard join would cause unnecessary data shuffling**.\n",
    "\n",
    "Your goal is to perform this join in the **most efficient way possible** using Spark.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Task\n",
    "\n",
    "Perform the following steps using Spark:\n",
    "\n",
    "1. **Read** the large fact dataset (events / transactions).\n",
    "2. **Read** the small country dimension dataset.\n",
    "3. Use a **broadcast join** to join the two datasets on country code.\n",
    "4. Create an enriched DataFrame with country name and region information.\n",
    "5. Use the enriched data for reporting or aggregation.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Assumptions\n",
    "\n",
    "- The fact dataset is large and distributed across partitions.\n",
    "- The country dimension dataset is very small (‚âà200 rows in real life).\n",
    "- The join key is:\n",
    "  - `fact.country` ‚Üí `dim.country_code`\n",
    "- Spark‚Äôs broadcast join threshold is sufficient for the dimension table.\n",
    "- Spark Serverless compute is being used.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Deliverables\n",
    "\n",
    "- **Enriched DataFrame** with country metadata\n",
    "- **Example Report:** Total transaction amount by region group\n",
    "\n",
    "### **Expected Columns (after join)**\n",
    "\n",
    "| country | country_name | region_group | amount |\n",
    "|--------|--------------|--------------|--------|\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Notes\n",
    "\n",
    "- Spark automatically distributes large datasets across executors.\n",
    "- Small lookup tables should be **broadcast** to avoid shuffling large data.\n",
    "- Broadcast joins are ideal for **fact‚Äìdimension** relationships.\n",
    "- This pattern is widely used in **data warehousing and analytics pipelines**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3ee209b-d3da-47b9-9d3e-6606e745ce2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† Solution Strategy (High-Level)\n",
    "\n",
    "1. **Read the large fact dataset** (events / transactions) from your catalog or database storage.\n",
    "2. **Read the small country dimension dataset** containing country metadata.\n",
    "3. Identify the join relationship:\n",
    "   - `fact.country` ‚Üí `dim.country_code`\n",
    "4. **Broadcast the small dimension DataFrame** so it is available on all executors.\n",
    "5. Perform a **broadcast hash join** between the fact and dimension tables.\n",
    "6. Use the enriched DataFrame (with country name and region) for downstream reports and aggregations.\n",
    "\n",
    "Spark handles:\n",
    "- Distributing the large fact table across executors\n",
    "- Sending the small dimension table to each executor once\n",
    "- Executing fast local hash joins without shuffling large data\n",
    "- Optimizing the join using its query planner\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11_joining_small_lookup_table_question",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
