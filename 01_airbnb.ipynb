{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c32923fe-1162-420f-8ea3-282e3369ad83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 18px; margin-bottom: 15px;\">\n",
    "  <img src=\"https://files.codebasics.io/v3/images/sticky-logo.svg\" alt=\"Codebasics Logo\" style=\"display: inline-block;\" width=\"130\">\n",
    "  <h1 style=\"font-size: 34px; color: #1f4e79; margin: 0; display: inline-block;\">Codebasics Practice Room - Data Engineering Bootcamp </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00d59cf3-5e7e-4749-81f7-6bd693b3fa5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üßëüèº‚Äçüîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a263a7b3-c7bb-4153-bb08-bbaf8a84d028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8k8WF3qOBlCZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, LongType, TimestampType\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c3cbcca-4e69-41f0-8659-ddd23238a017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# ‚öôÔ∏è Databricks Unity Catalog Setup (Auto)\n",
    "# --------------------------------------------\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "catalog_name = \"practice_db_catalog\"\n",
    "schema_name = \"airbnb\"\n",
    "volume_name = \"data_volume\"\n",
    "\n",
    "# 1Ô∏è‚É£ Create Catalog if not exists\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "print(f\"‚úÖ Catalog `{catalog_name}` ready.\")\n",
    "\n",
    "# 2Ô∏è‚É£ Create Schema (Database) if not exists\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "print(f\"‚úÖ Schema `{schema_name}` created inside `{catalog_name}`.\")\n",
    "\n",
    "# 3Ô∏è‚É£ Create Volume if not exists\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")\n",
    "print(f\"‚úÖ Volume `{volume_name}` created inside `{catalog_name}.{schema_name}`\")\n",
    "\n",
    "# 4Ô∏è‚É£ Set current context\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE {schema_name}\")\n",
    "\n",
    "# 5Ô∏è‚É£ Define volume-backed paths\n",
    "base_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/airbnb\"\n",
    "raw_path = f\"{base_path}/raw\"\n",
    "clean_path = f\"{base_path}/clean\"\n",
    "silver_path = f\"{base_path}/silver\"\n",
    "\n",
    "# 6Ô∏è‚É£ Create directories inside the volume\n",
    "dbutils.fs.mkdirs(raw_path)\n",
    "dbutils.fs.mkdirs(clean_path)\n",
    "dbutils.fs.mkdirs(silver_path)\n",
    "\n",
    "print(\"‚úÖ Paths initialized successfully:\")\n",
    "print(f\"Raw: {raw_path}\")\n",
    "print(f\"Clean: {clean_path}\")\n",
    "print(f\"Silver: {silver_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a55bf2b7-c717-447b-b00f-0b4a7254ea29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIHeYDRKbcsl",
    "outputId": "8009cf20-4136-46ae-fd54-d82016094a98"
   },
   "outputs": [],
   "source": [
    "# üßÆ Generate Airbnb listings dataset (Spark-native version)\n",
    "from pyspark.sql import Row\n",
    "import random, datetime\n",
    "\n",
    "# --------------------------------\n",
    "# Configuration\n",
    "# --------------------------------\n",
    "\n",
    "random.seed(42) # ‚úÖ reproducibility\n",
    "\n",
    "num_records = 600  # Adjust as needed\n",
    "\n",
    "amenities_pool = [\n",
    "    \"Wifi\", \"Kitchen\", \"Washer\", \"Dryer\", \"TV\", \"Essentials\", \"Air conditioning\",\n",
    "    \"Heating\", \"Pool\", \"Hot tub\", \"Balcony\", \"Garden\", \"Parking\", \"Fireplace\",\n",
    "    \"Sea view\", \"Mountain view\", \"Pet friendly\", \"Gym\", \"Breakfast\", \"Workspace\"\n",
    "]\n",
    "\n",
    "property_types = [\n",
    "    \"Studio Apartment\", \"Private Room\", \"Entire Home\", \"Cottage\", \"Villa\",\n",
    "    \"Cabin\", \"Loft\", \"Guest Suite\", \"Bungalow\", \"Condo\"\n",
    "]\n",
    "\n",
    "cities = [\"Mumbai\", \"Bangalore\", \"Hyderabad\", \"Chennai\", \"Pune\", \"Delhi\", \"Goa\"]\n",
    "boolean_variants = [True, False, \"true\", \"false\", \"Yes\", \"No\", \"yes\", \"no\", \"TRUE\", \"FALSE\"]\n",
    "\n",
    "# --------------------------------\n",
    "# Generate data as list of Rows\n",
    "# --------------------------------\n",
    "data = []\n",
    "for i in range(1, num_records + 1):\n",
    "    created_date = datetime.date(2025, 1, 1) + datetime.timedelta(days=random.randint(0, 300))\n",
    "    last_booked_date = created_date + datetime.timedelta(days=random.randint(1, 60))\n",
    "\n",
    "    data.append(Row(\n",
    "        id=100 + i,\n",
    "        name=f\"{random.choice(['Cozy', 'Modern', 'Luxury', 'Spacious', 'Budget'])} \"\n",
    "             f\"{random.choice(property_types)} in {random.choice(cities)}\",\n",
    "        city=random.choice(cities),\n",
    "        price_per_night=random.randint(1000, 10000),\n",
    "        amenities=random.sample(amenities_pool, random.randint(3, 8)),\n",
    "        has_parking=random.choice(boolean_variants),\n",
    "        is_superhost=random.choice(boolean_variants),\n",
    "        created_date=str(created_date),\n",
    "        last_booked_date=str(last_booked_date)\n",
    "    ))\n",
    "\n",
    "# --------------------------------\n",
    "# Convert to Spark DataFrame\n",
    "# --------------------------------\n",
    "df_raw = spark.createDataFrame(data)\n",
    "\n",
    "# --------------------------------\n",
    "# Write directly to UC Volume (JSON format)\n",
    "# --------------------------------\n",
    "raw_path = \"/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/raw/listings.json\"\n",
    "\n",
    "df_raw.write.mode(\"overwrite\").json(raw_path)\n",
    "print(f\"‚úÖ Successfully generated {num_records} Airbnb listings and saved to:\")\n",
    "print(f\"üìÇ {raw_path}\")\n",
    "\n",
    "# --------------------------------\n",
    "# Quick sanity check\n",
    "# --------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98844068-0fe8-485d-bf1b-d6b7562737ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "p6W0vNsRX4Ch"
   },
   "source": [
    "\n",
    "# ‚ùì Scenario Question: Airbnb ‚Äî Clean Listing Amenities (PySpark) [Easy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c63d114f-75c9-42c9-90d2-72710f619d8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BCQ8sDM6cF2d"
   },
   "source": [
    "## üóÇÔ∏è Scenario\n",
    "\n",
    "You are working with raw **Airbnb listing data** ingested from multiple sources.  \n",
    "Each listing contains property details and a **nested list of amenities**.  \n",
    "The goal is to **clean, normalize, and store** this data for downstream analysis.\n",
    "\n",
    "The data is available as a JSON file (`listings.json`) in the **Bronze layer**, which now needs to be transformed into a clean **Silver Delta Table**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Task\n",
    "\n",
    "Perform the following transformations:\n",
    "\n",
    "1. **Read** the input data from `listings.json` using Spark.  \n",
    "2. **Explode** the `amenities` array so that each row contains a single amenity.  \n",
    "3. **Normalize** boolean-like columns (e.g., `\"true\"`, `\"false\"`, `\"yes\"`, `\"no\"`) into proper boolean (`True` / `False`) Spark data types.  \n",
    "4. **Rename** or select only the relevant columns for downstream use.  \n",
    "5. **Save** the cleaned DataFrame in **Delta format** to the **Silver layer** path:  \n",
    "   `/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/silver/listings.json` \n",
    "\n",
    "---\n",
    "\n",
    "## üß© Assumptions\n",
    "\n",
    "- The input file `listings.json` exists in the **Bronze** path:  \n",
    "  `/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/raw/listings.json`\n",
    "- The `amenities` field may contain an array or a stringified array.  \n",
    "- Boolean columns may contain values like `\"TRUE\"`, `\"Yes\"`, `\"0\"`, `\"1\"`, etc.  \n",
    "- The final cleaned DataFrame should contain only essential columns:  \n",
    "  `id`, `name`, `amenity`, `has_parking`, and `is_superhost`.  \n",
    "- Handle missing or malformed columns gracefully (e.g., cast to `null`).  \n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Deliverables\n",
    "\n",
    "- **Output Format:** Delta table written to Silver  \n",
    "- **Output Path:** `/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/silver/listings.json`\n",
    "\n",
    "| **Expected Columns** | `id`, `name`, `amenity`, `has_parking`, `is_superhost` |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Notes\n",
    "\n",
    "- Use `pyspark.sql.functions.explode()` to expand the amenities array.  \n",
    "- Use `F.when()` or `F.col().cast(\"boolean\")` for boolean normalization.  \n",
    "- Use clear column aliases for readability.  \n",
    "- Validate the write by reading from the Silver path and displaying the first few rows.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Example Output (simplified)\n",
    "\n",
    "| id  | name               | amenity          | has_parking | is_superhost |\n",
    "|-----|--------------------|------------------|--------------|---------------|\n",
    "| 101 | Cozy Beach House   | Wifi             | true         | false         |\n",
    "| 101 | Cozy Beach House   | Ocean View       | true         | false         |\n",
    "| 102 | City Apartment     | Air Conditioning | false        | true          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18dd77a6-b3b7-41ce-acd1-b0ac3cbea235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GSTZBIoGcjOM"
   },
   "source": [
    "## üõ¢Ô∏èInput data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "498f5902-c502-47b1-8c1a-8b39ab4817c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UduvjFkYN09B",
    "outputId": "05f4ec55-229a-4706-b526-aa5b8b330324"
   },
   "outputs": [],
   "source": [
    "display(df_raw.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23444b5-e3e5-4f73-b36a-297a7b9467d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ijBDbcY2enlu"
   },
   "source": [
    "# üìù Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b397788-4159-4777-8161-0cb8d0a61b8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b5nNsMI_eiYy"
   },
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Your Solution Here\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Steps:\n",
    "# 1. Read the JSON file\n",
    "# 2. Explode the amenities\n",
    "# 3. Normalize boolean-like fields and retrun the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cebd2b2e-bfbd-47bb-9b21-d47cce9ce6be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2h40PeBJSkdK"
   },
   "source": [
    "## üîç Validation Questions\n",
    "\n",
    "After creating the final DataFrame (`df_final`), answer these to check your understanding:\n",
    "\n",
    "1. How many amenities are listed for the property with **ID = 101**?  \n",
    "2. How many listings have **`is_superhost = true`**?  \n",
    "3. What are the **unique amenities** available for listing **ID = 103**?  \n",
    "4. Count how many listings have **`has_parking = true`**.  \n",
    "5. For each listing, how many total amenities are available? (Hint: use `groupBy().count()`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "441c7d84-085b-476a-b82b-07d17d85d144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw.limit(10).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6246c40-a924-4c2f-b3fb-532c0481fb2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "__HYDc_-S9jA"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Exploading the amenities column\n",
    "df_silver = df_raw.select(\"id\", \"name\", F.explode(\"amenities\").alias(\"amenities\"), \"has_parking\", \"is_superhost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e89944-c8f2-44fc-97ef-785d959f0ae7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55093218-7be6-4fcb-bdb2-3648fee0d060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5349099-26c7-495b-8d0f-89a59378fb51",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 18"
    }
   },
   "outputs": [],
   "source": [
    "#Standarizing has_parking coloumn\n",
    "df_silver = df_silver.withColumn(\"has_parking\", F.when(F.col(\"has_parking\").isin([\"true\", \"TRUE\", \"Yes\", \"yes\", \"True\"]), True)\n",
    "                                                      .otherwise(False).cast(\"boolean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a1bca1d-3d3d-45b3-a273-b66292fc891b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Standarizing is_superhost coloumn\n",
    "df_final = df_silver.withColumn(\"is_superhost\", F.when(F.col(\"is_superhost\").isin([\"true\", \"TRUE\", \"Yes\", \"yes\", \"True\"]), True)\n",
    "                                                      .otherwise(False).cast(\"boolean\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8347dacc-9430-4065-bf08-a6b0756edc51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#How many amenities are listed for the property with ID = 101?\n",
    "df_final.filter(F.col(\"id\") == '101').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a02dfe9-3cf9-4855-9f0c-6e493dbcd6ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#How many listings have is_superhost = true?\n",
    "df_final.filter(F.col(\"is_superhost\") == True).select(\"id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9234386c-397a-45a2-b52a-732f38687cc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#What are the unique amenities available for listing ID = 103?\n",
    "df_final.filter(F.col(\"id\") == 103).select(\"amenities\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04e3791c-9fce-4279-baba-de5fa16f441f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Count how many listings have has_parking = true\n",
    "df_final.filter(F.col(\"has_parking\") == True).select(\"id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9f7085-7481-489b-9d9e-4834da4bb2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#For each listing, how many total amenities are available? (Hint: use groupBy().count().)\n",
    "df_final.groupBy(\"id\").agg(F.countDistinct(\"amenities\").alias(\"total_amenities\")).orderBy(\"id\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5838b324-444a-48ba-bc58-010617425f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Writting it to the silver in the file '/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/silver/listings.json'\n",
    "\n",
    "final_out_path = '/Volumes/practice_db_catalog/airbnb/data_volume/airbnb/silver/listings.json'\n",
    "\n",
    "df_final.write.mode(\"Overwrite\").json(final_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b932e91-74b2-4113-84f8-0b67f2b914be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_airbnb",
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [
    "p6W0vNsRX4Ch",
    "ijBDbcY2enlu"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
