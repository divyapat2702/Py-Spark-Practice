{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d493d205-0d6d-43c5-b959-8c966477deeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; align-items: center; gap: 18px; margin-bottom: 15px;\">\n",
    "  <img src=\"https://files.codebasics.io/v3/images/sticky-logo.svg\" alt=\"Codebasics Logo\" style=\"display: inline-block;\" width=\"130\">\n",
    "  <h1 style=\"font-size: 34px; color: #1f4e79; margin: 0; display: inline-block;\">Codebasics Practice Room - Data Engineering Bootcamp </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe92f04f-b724-4680-8114-bd92d82ae4a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### üîó Joining Small Lookup Tables Efficiently in Spark\n",
    "\n",
    "This notebook demonstrates how Apache Spark can **efficiently join a very large fact table**\n",
    "with a **small lookup (dimension) table** using a **broadcast join**.\n",
    "\n",
    "This is a common real-world pattern in analytics and data engineering,\n",
    "especially in **star-schema‚Äìlike designs**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e2bb9a7-5d1d-4928-a730-562dd860be41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìÇ Dataset\n",
    "\n",
    "### Fact Table (Large)\n",
    "**Dataset Name:** `big_events_50k.csv`  \n",
    "Represents a large transactional or event-level dataset.\n",
    "\n",
    "### Dimension Table (Small)\n",
    "**Dataset Name:** `country_dim.csv`  \n",
    "Contains country metadata such as country name and region.\n",
    "\n",
    "> ‚ö†Ô∏è In real-world systems, the fact table can contain **millions or billions of rows**,  \n",
    "while the country dimension usually contains **only a few hundred rows**.\n",
    "\n",
    "Both datasets are assumed to be available in **your catalog / database storage**.\n",
    "\n",
    "### Example Columns\n",
    "\n",
    "**Fact Table**\n",
    "- `event_id`\n",
    "- `event_time`\n",
    "- `country`\n",
    "- `amount`\n",
    "\n",
    "**Country Dimension**\n",
    "- `country_code`\n",
    "- `country_name`\n",
    "- `region_group`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3adcd9af-6e0e-4df2-9071-83269afa95b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üóÇÔ∏è Scenario\n",
    "\n",
    "You are working with a **large fact table** containing transaction or event data.\n",
    "Each record includes a **country code**, but no descriptive country information.\n",
    "\n",
    "To enrich the data for reporting, you need to join it with a **small country dimension table**\n",
    "that contains:\n",
    "- full country names\n",
    "- regional groupings (e.g., Asia, Europe, Americas)\n",
    "\n",
    "Because the fact table is large and the dimension table is very small,\n",
    "a **standard join would cause unnecessary data shuffling**.\n",
    "\n",
    "Your goal is to perform this join in the **most efficient way possible** using Spark.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Task\n",
    "\n",
    "Perform the following steps using Spark:\n",
    "\n",
    "1. **Read** the large fact dataset (events / transactions).\n",
    "2. **Read** the small country dimension dataset.\n",
    "3. Use a **broadcast join** to join the two datasets on country code.\n",
    "4. Create an enriched DataFrame with country name and region information.\n",
    "5. Use the enriched data for reporting or aggregation.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Assumptions\n",
    "\n",
    "- The fact dataset is large and distributed across partitions.\n",
    "- The country dimension dataset is very small (‚âà200 rows in real life).\n",
    "- The join key is:\n",
    "  - `fact.country` ‚Üí `dim.country_code`\n",
    "- Spark‚Äôs broadcast join threshold is sufficient for the dimension table.\n",
    "- Spark Serverless compute is being used.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Deliverables\n",
    "\n",
    "- **Enriched DataFrame** with country metadata\n",
    "- **Example Report:** Total transaction amount by region group\n",
    "\n",
    "### **Expected Columns (after join)**\n",
    "\n",
    "| country | country_name | region_group | amount |\n",
    "|--------|--------------|--------------|--------|\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Notes\n",
    "\n",
    "- Spark automatically distributes large datasets across executors.\n",
    "- Small lookup tables should be **broadcast** to avoid shuffling large data.\n",
    "- Broadcast joins are ideal for **fact‚Äìdimension** relationships.\n",
    "- This pattern is widely used in **data warehousing and analytics pipelines**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3ee209b-d3da-47b9-9d3e-6606e745ce2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† Solution Strategy (High-Level)\n",
    "\n",
    "1. **Read the large fact dataset** (events / transactions) from your catalog or database storage.\n",
    "2. **Read the small country dimension dataset** containing country metadata.\n",
    "3. Identify the join relationship:\n",
    "   - `fact.country` ‚Üí `dim.country_code`\n",
    "4. **Broadcast the small dimension DataFrame** so it is available on all executors.\n",
    "5. Perform a **broadcast hash join** between the fact and dimension tables.\n",
    "6. Use the enriched DataFrame (with country name and region) for downstream reports and aggregations.\n",
    "\n",
    "Spark handles:\n",
    "- Distributing the large fact table across executors\n",
    "- Sending the small dimension table to each executor once\n",
    "- Executing fast local hash joins without shuffling large data\n",
    "- Optimizing the join using its query planner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f15bde6-c9e0-4b6c-8a64-839981a999cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import broadcast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4ee88f0-85d1-45ec-9c0e-dc581300fbf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact table (large)\n",
    "fact_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .csv(\"your_data\")\n",
    ")\n",
    "\n",
    "# Country dimension (small)\n",
    "country_dim_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .csv(\"your_data\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "609d075e-3460-4177-8666-a63b879053aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fact_df.printSchema()\n",
    "country_dim_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ced7fea-2ab9-4b8f-a51c-77b37daf6b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üõ¢Ô∏è Input Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27cde33c-c73e-45df-ac14-e2787d357e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(fact_df.limit(5))\n",
    "display(country_dim_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86bb8559-c86a-41c7-8cfe-6610089599d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîó Broadcast Join (Fact ‚Üí Dimension)\n",
    "\n",
    "Since the country dimension is very small,\n",
    "we broadcast it to all executors to perform a **fast hash join**\n",
    "without shuffling the large fact table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84aceba0-66c1-4e74-879f-c93e3b129e0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df = (\n",
    "    fact_df.alias(\"f\")\n",
    "           .join(\n",
    "               broadcast(country_dim_df).alias(\"d\"),\n",
    "               F.col(\"f.country\") == F.col(\"d.country_code\"),\n",
    "               \"left\"\n",
    "           )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65f234e-190e-4a0f-8755-8ce55a5356db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìä Example Report\n",
    "\n",
    "### Business Question:\n",
    "**What is the total transaction amount by region group?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c124bb83-f57e-4d30-b07f-5f26001743db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agg_df = (\n",
    "    joined_df\n",
    "        .groupBy(\"region_group\")\n",
    "        .agg(F.sum(\"amount\").alias(\"total_amount\"))\n",
    ")\n",
    "\n",
    "display(agg_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5b27a8d-aab5-47dc-a8f7-35f8ad754616",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß† Why This Is Efficient\n",
    "\n",
    "- The **large fact table is not shuffled** across the cluster.\n",
    "- The **small dimension table is sent once** to all executors.\n",
    "- Spark performs a **local hash join** on each executor.\n",
    "- This dramatically reduces network I/O and execution time.\n",
    "\n",
    "This approach works best when the dimension table size is\n",
    "well below Spark‚Äôs broadcast threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c84dc78-8061-4e66-b93a-c4e16e46078e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚öôÔ∏è Why This Solution Scales\n",
    "\n",
    "### Key Spark Features Used:\n",
    "- **Broadcast Hash Join**\n",
    "- **Distributed Processing**\n",
    "- **Parallel Execution**\n",
    "- **Lazy Evaluation**\n",
    "- **Query Optimization**\n",
    "\n",
    "üí° The same pattern works for:\n",
    "- 50k rows or 500M rows in the fact table\n",
    "- Any small lookup table (countries, statuses, categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ccdffe-d001-4014-9d3b-9cb5bf3dfe6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "- Large fact + small dimension joins are extremely common.\n",
    "- Broadcasting the small table avoids expensive shuffles.\n",
    "- This results in faster, more scalable Spark jobs.\n",
    "- Broadcast joins are a **best practice** in analytics pipelines.\n",
    "\n",
    "This notebook demonstrates a **production-ready Spark optimization pattern**\n",
    "used across real-world data platforms.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_joining_small_lookup_table_solution",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
